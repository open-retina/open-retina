---
title: Dataset Reference
---

# Dataset Reference

TODO this page was partly generated by AI. needs reviewing.

OpenRetina provides integrated support for several published retinal datasets, enabling easy access to experimental data for training and evaluating neural network models. This page describes the available datasets, their structure, and how to use them.

## Supported Datasets

### Höfling et al., 2024

**Paper**: ["A chromatic feature detector in the retina signals visual context changes"](https://doi.org/10.7554/eLife.86860) (eLife 2024)

**Species**: Mouse

**Recording Method**: Two-photon calcium imaging of the ganglion cell layer.

**Data Characteristics**:
- **Stimulus channels**: 2 (UV and Green wavelengths)
- **Spatial resolution**: 16×18 (low-res) or 64×72 (high-res)
- **Temporal resolution**: 30 Hz
- **Cell types**: 46 functionally defined RGC types following Baden et al. 2016 classification
- **Stimulus types**: Natural movies, chirp stimuli, moving bars

**Dataset Structure**:
```python
# Cell type groups
- OFF cells (types 1-9)
- ON-OFF cells (types 10-14) 
- Fast ON cells (types 15-20)
- Slow ON cells (types 21-28)
- Uncertain RGCs (types 29-32)
- Amacrine cells (types 33-46)

# Data organization
- Natural scenes: 108 clips of 150 frames each
- Responses: Calcium fluorescence traces for individual neurons
- ROI coordinates: Spatial positions of recorded cells
```

**Usage**:
```python
from openretina.data_io.hoefling_2024 import natmov_dataloaders_v2

# Load dataset
dataloaders = natmov_dataloaders_v2(
    responses_path="path/to/responses.h5",
    stimuli_path="path/to/stimuli.h5",
    batch_size=32,
    train_chunk_size=50
)
```

**Data Access**: Available on [Hugging Face](https://huggingface.co/datasets/open-retina/open-retina)

### Karamanlis et al., 2024

**Paper**: ["Nonlinear receptive fields evoke redundant retinal coding of natural scenes"](https://doi.org/10.1038/s41586-024-08212-3) (Nature 2024)

**Species**: Mouse and marmoset

**Recording Method**: Multi-electrode array recordings

**Data Characteristics**:
- **Stimulus types**: TODO
- **Temporal resolution**: Variable (stimulus-dependent)
- **Response type**: Spike counts and firing rates
- **Cell types**: Multiple RGC types from primate retina

**Stimulus Types**:
- `fixationmovie`: Natural movie sequences
- `frozencheckerflicker`: Checkerboard patterns with temporal modulation
- `gratingflicker`: Oriented gratings with flicker
- `imagesequence`: Static image presentations

**Usage**:
```python
from openretina.data_io.karamanlis_2024 import load_all_stimuli, load_all_responses

# Load stimuli
stimuli = load_all_stimuli(
    base_data_path="path/to/data",
    stim_type="fixationmovie",
    downsampled_size=(32, 32)
)

# Load responses
responses = load_all_responses(
    base_data_path="path/to/data",
    stim_type="fixationmovie"
)
```

**Data Access**: TODO

### Maheswaranathan et al., 2023

**Paper**: ["Interpreting the retinal neural code for natural scenes: From computations to neurons"](https://doi.org/10.1016/j.neuron.2023.06.007) (Neuron 2023)

**Species**: Salamander 

**Recording Method**: Multi-electrode array recordings

**Data Characteristics**:
- **Stimulus types**: Natural scenes, white noise
- **Temporal resolution**: 30 Hz
- **Clip length**: 90 frames (3 seconds)
- **Response types**: Firing rates at 5ms, 10ms, or 20ms bins
- **Normalization**: Configurable firing rate scaling

**Response Types**:
- `firing_rate_5ms`: High temporal resolution
- `firing_rate_10ms`: Medium temporal resolution  
- `firing_rate_20ms`: Lower temporal resolution (default)

**Usage**:
```python
from openretina.data_io.maheswaranathan_2023 import load_all_stimuli, load_all_responses

# Load natural scene stimuli
stimuli = load_all_stimuli(
    base_data_path="path/to/neural_code_data",
    stim_type="naturalscene",
    normalize_stimuli=True
)

# Load corresponding responses
responses = load_all_responses(
    base_data_path="path/to/neural_code_data",
    response_type="firing_rate_20ms",
    stim_type="naturalscene"
)
```

**Data Access**: 
- Original: [Stanford Digital Repository](https://doi.org/10.25740/rk663dm5577)
- Mirror: [Hugging Face](https://huggingface.co/datasets/open-retina/open-retina/resolve/main/baccus_lab/maheswaranathan_2023/neural_code_data.zip)

## Artificial Stimuli

OpenRetina also provides synthetic stimulus generation for testing and development:

### Available Artificial Stimuli

**Chirp Stimulus**:
- Duration: 32.9 seconds
- Temporal frequency sweep
- Available resolutions: 18×16, 72×64

**Moving Bar Stimulus**:
- 8 motion directions
- Duration: ~4 seconds per direction
- Available resolutions: 18×16, 72×64

**White Noise**:
- Spatiotemporal random patterns
- Configurable dimensions and statistics

**Usage**:
```python
from openretina.data_io.artificial_stimuli import load_stimulus

# Load chirp stimulus
chirp = load_stimulus("chirp", resolution="18x16", normalize=True)

# Load moving bar stimulus  
moving_bar = load_stimulus("moving_bar", resolution="72x64", normalize=True)
```

## Custom Data Integration

TODO write

### Data Format Requirements

**Stimulus Data**:
- Format: `(channels, time, height, width)` for movies
- Type: `numpy.ndarray` or `torch.Tensor`
- Channels: Number of wavelengths/colors
- Time: Temporal frames
- Spatial: Height × Width pixels

**Response Data**:
- Format: `(time, neurons)` for neural responses
- Type: `numpy.ndarray` or `torch.Tensor`
- Time: Same temporal resolution as stimuli
- Neurons: Number of recorded cells

**Metadata** (optional but recommended):
- ROI coordinates: `(neurons, 2)` spatial positions
- Cell type labels: `(neurons,)` functional classifications
- Session information: Experimental metadata
- Anything else that could be relevant for downstream analyses.


## Data Access and Licensing

### Download Instructions

**Automatic Download**:
TODO explain and give an example on how we also parse huggingface paths.


**Manual Download**:
1. Visit the Hugging Face repository: [open-retina/open-retina](https://huggingface.co/datasets/open-retina/open-retina)
2. Download specific dataset files
3. Extract to local directory
4. Point dataloaders to local path

### Licensing

All datasets are shared under **CC-BY Share-Alike** license. While `openretina` provides a convenient mirror
to these through HuggingFace, proper attribution should be given to the original authors and the original data sources:

TODO add also data sources, not only papers.

- **Höfling et al.**: [doi:10.7554/eLife.86860](https://doi.org/10.7554/eLife.86860)
- **Karamanlis et al.**: [doi:10.1038/s41586-024-08212-3](https://doi.org/10.1038/s41586-024-08212-3)
- **Maheswaranathan et al.**: [doi:10.1016/j.neuron.2023.06.007](https://doi.org/10.1016/j.neuron.2023.06.007)

### Getting Help

For dataset-specific issues:
1. Check original paper documentation
2. Review example notebooks in the repository
3. Open issues on [GitHub](https://github.com/open-retina/open-retina/issues)
