{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b388760",
   "metadata": {},
   "source": [
    "In this notebook we will go a bit further in the training of a Core/Readout model. Using once again data from Hoefling et al., 2024: [\"A chromatic feature detector in the retina signals visual context changes\"](https://elifesciences.org/articles/86860).\n",
    "\n",
    "We will see how we can search the hyperparameter space using Hydra, while doing minimal changes to the configuration files. It can only be used using the CLI version of open_retina.\n",
    "\n",
    "The recommended sweeper is the library optuna https://optuna.org. It's already integrated in the pipeline. To learn more about the keyword that can be used, see here : https://hydra.cc/docs/plugins/optuna_sweeper/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc720c2",
   "metadata": {},
   "source": [
    "# Hyperparameter Search Configuration\n",
    "\n",
    "The hyperparameter search can be fully defined in the main config file of your experiment.\n",
    "\n",
    "Let's compare the configs `hoefling_2024_core_readout_low_res` and `hoefling_2024_core_readout_low_res_hyperparams_search`:\n",
    "\n",
    "1. Added Optuna sweeper overrides. Feel free to use a different sampler:\n",
    "```yaml\n",
    "    - `override hydra/sweeper: optuna`\n",
    "    - `override hydra/sweeper/sampler: tpe`\n",
    "```\n",
    "\n",
    "2. Defined objective target for optimization. It has to be one of the column of the valdiation object:\n",
    "    ```yaml\n",
    "    objective_target: val_validation_loss  # Must be a computed validation metric\n",
    "    ```\n",
    "\n",
    "3. Configured the Hydra sweeper section:\n",
    "    ```yaml\n",
    "    hydra:\n",
    "      run:\n",
    "         dir: ${paths.log_dir}\n",
    "      sweeper:\n",
    "         sampler: # Configurable sampler parameters\n",
    "            seed: 42\n",
    "         direction: maximize \n",
    "         study_name: ${exp_name}\n",
    "         storage: null\n",
    "         n_trials: 20 # Control over trials and parallel jobs\n",
    "         n_jobs: 1\n",
    "         params: # Parameter optimization using Optuna keywords (choice, interval)\n",
    "            # Example optimizes hidden channels and core spatial regularization\n",
    "            model.hidden_channels: choice([8, 8, 8, 8], [16, 16, 16, 16], [32, 32, 32, 32])\n",
    "            model.core_gamma_input: interval(1e-5, 1e-2)\n",
    "    ```\n",
    "4. Optional. Enable MLflow logger\n",
    "```yaml\n",
    "  - logger:\n",
    "    - tensorboard\n",
    "    - csv\n",
    "    - mlflow\n",
    "```\n",
    "\n",
    "You should be able to adapt those 4 steps to any particular needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6cf516",
   "metadata": {},
   "source": [
    "# Launching the search\n",
    "\n",
    "We will use the same command as usual, adding the option --multirun.\n",
    "\n",
    "```bash\n",
    "openretina train --config-name \"hoefling_2024_core_readout_low_res_hyperparams_search\" --multirun\n",
    "```\n",
    "\n",
    "If the option --multirun is not selected, the sweeper section will be ignore, launching a single training session with the default parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c5401",
   "metadata": {},
   "source": [
    "# Viewing and Analyzing Results with MLflow\n",
    "\n",
    "This tutorial demonstrates how to visualize and analyze your experiment results using MLflow's web interface. While we use MLflow in this example, you can adapt these concepts to other logging tools like TensorBoard or CSV loggers. It's also relativaly easy to save additional artifacts to tensorboard or mlflow using pytorch lightning callbacks.\n",
    "\n",
    "## Starting the MLflow Server\n",
    "\n",
    "Launch the MLflow UI by running the following command:\n",
    "\n",
    "```bash\n",
    "mlflow server --backend-store-uri ./openretina_assets/mlflow --host 0.0.0.0 --port 5000\n",
    "```\n",
    "\n",
    "**Important:** Make sure to specify the correct `--backend-store-uri` path where your MLflow data is stored.\n",
    "\n",
    "## Navigating the MLflow Interface\n",
    "\n",
    "1. **Access the UI**: Open your browser and navigate to `http://localhost:5000`\n",
    "\n",
    "2. **Locate Your Experiment**: Look for your experiment name in the left sidebar\n",
    "\n",
    "3. **Customize the Results View**:\n",
    "   - Click on \"Columns\" to add metrics to the table view\n",
    "   - Add your target metric (e.g., `val_validation_loss`)\n",
    "   - Sort runs by clicking on any column header\n",
    "   - Use filters to narrow down results\n",
    "\n",
    "## Comparing Multiple Runs\n",
    "\n",
    "To analyze and compare different runs:\n",
    "\n",
    "1. Select multiple runs by checking the boxes next to them\n",
    "2. Click the \"Compare\" button at the top\n",
    "3. Access various comparison views:\n",
    "   - **Metrics plots**: Visualize how metrics changed across runs\n",
    "   - **Parameter comparisons**: See how different hyperparameters affected performance\n",
    "   - **Model artifacts**: Review saved models and configurations\n",
    "\n",
    "## Programmatic Access\n",
    "\n",
    "For batch analysis or automation, you can retrieve the best run programmatically:\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "# Connect to your MLflow tracking server\n",
    "mlflow.set_tracking_uri(\"./openretina_assets/mlflow\")\n",
    "\n",
    "# Get the best run from an experiment\n",
    "experiment_id = mlflow.get_experiment_by_name(\"your_experiment_name\").experiment_id\n",
    "best_run = mlflow.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    order_by=[\"metrics.val_validation_loss DESC\"],\n",
    "    max_results=1\n",
    ").iloc[0]\n",
    "\n",
    "# Load the best model\n",
    "best_model = mlflow.sklearn.load_model(f\"runs:/{best_run.run_id}/model\")\n",
    "```\n",
    "\n",
    "## What's Stored in MLflow by default in open retina\n",
    "\n",
    "Each run automatically saves:\n",
    "- Model weights and artifacts\n",
    "- Training configuration and hyperparameters\n",
    "- Metrics logged during training\n",
    "- Environment details and dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b862b331",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4a9f089",
   "metadata": {},
   "source": [
    "# Viewing and analyzing results with tensorboard\n",
    "\n",
    "I you'd prefer to use tensorboard, you still can. Here is how to access the UI.\n",
    "\n",
    "## Starting the Tensorboard Server\n",
    "\n",
    "Launch the Tensorboard UI by running the following command:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir ./openretina_assets/runs/[(your_experiment_name)] --host 0.0.0.0 --port 6000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197687b0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_retina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
