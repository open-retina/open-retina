{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will train a Core/Readout model on data from Hoefling et al., 2024: [\"A chromatic feature detector in the retina signals visual context changes\"](https://elifesciences.org/articles/86860).\n",
    "\n",
    "We will closely follow the structure of our unified training script, `openretina.cli.train.py`, including using Hydra to import and examine model config files. \n",
    "\n",
    "Note that using `openretina.cli.train.py`, and the corresponding command `openretina train` is the recommended way to run model training, as for some configurations it can take some time. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import hydra\n",
    "import lightning\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "from openretina.data_io.base import compute_data_info\n",
    "from openretina.data_io.cyclers import LongCycler, ShortCycler\n",
    "from openretina.data_io.hoefling_2024.dataloaders import natmov_dataloaders_v2\n",
    "from openretina.data_io.hoefling_2024.responses import filter_responses, make_final_responses\n",
    "from openretina.data_io.hoefling_2024.stimuli import movies_from_pickle\n",
    "from openretina.eval.metrics import correlation_numpy, feve\n",
    "from openretina.models.core_readout import CoreReadout\n",
    "from openretina.utils.file_utils import get_local_file_path\n",
    "from openretina.utils.h5_handling import load_h5_into_dict\n",
    "from openretina.utils.misc import CustomPrettyPrinter\n",
    "from openretina.utils.plotting import (\n",
    "    numpy_to_mp4_video,\n",
    ")\n",
    "\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")  # to display logs in jupyter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "pp = CustomPrettyPrinter(indent=4, max_lines=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import also the global config file for this model using hydra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=os.path.join(\"..\", \"configs\"), version_base=\"1.3\"):\n",
    "    cfg = hydra.compose(config_name=\"goldin_2022_core_readout.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in loading data is determining from where it will be fetched / stored.\n",
    "\n",
    "Let's see how this is handled in the configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'cache_dir': '${oc.env:OPENRETINA_CACHE_DIRECTORY}',\n",
      "    'data_dir': '/home/baptiste/Documents/LabPipelines/open-retina/notebooks/data/omarre_lab/goldin_2023/goldin_2023_data.zip',\n",
      "    'log_dir': '.',\n",
      "    'output_dir': '${hydra:runtime.output_dir}'}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(cfg.paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config contains the path from where files will be downloaded, and also requires the `cache_dir` to be set by the user: this is the directory where the data will be stored on download.\n",
    "\n",
    "When using the training script, if cache_dir is not set by the user in the config files or somewhere in the script, this will fall back to the `OPENRETINA_CACHE_DIRECTORY` environment variable, which by default points to `~/openretina_cache`.\n",
    "\n",
    "If set, the `cache_dir` is also what the package will use in place of the default openretina cache folder. Let's set both here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_chosen_root_folder = \".\"  # Change this with your desired path.\n",
    "\n",
    "cfg.paths.cache_dir = your_chosen_root_folder\n",
    "\n",
    "# We will also overwrite the output directory for the logs/model to the local folder.\n",
    "cfg.paths.log_dir = your_chosen_root_folder\n",
    "cfg.paths.output_dir = your_chosen_root_folder\n",
    "\n",
    "os.environ[\"OPENRETINA_CACHE_DIRECTORY\"] = your_chosen_root_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of the stimuli is achieved, in the training script, via:\n",
    "```\n",
    "movies_dict = hydra.utils.call(cfg.data_io.stimuli)\n",
    "```\n",
    "\n",
    "Let's unpack it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   '_convert_': 'object',\n",
      "    '_target_': 'openretina.data_io.goldin_2022.stimuli.load_all_stimuli',\n",
      "    'base_data_path': '${paths.data_dir}',\n",
      "    'normalize_stimuli': True,\n",
      "    'specie': 'axolotl and mouse',\n",
      "    'stim_type': 'naturalscene'}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(cfg.data_io.stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cache_dir': '.', 'data_dir': '/home/baptiste/Documents/LabPipelines/open-retina/notebooks/data/omarre_lab/goldin_2023/goldin_2023_data.zip', 'log_dir': '.', 'output_dir': '.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, using the `get_local_file_path` function, if `file_path` is not a local fiile, it will be downloaded to the cache folder and read from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigAttributeError",
     "evalue": "Key 'movies_path' is not in struct\n    full_key: paths.movies_path\n    object_type=dict",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConfigAttributeError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m movies_path = get_local_file_path(file_path=\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmovies_path\u001b[49m, cache_folder=cfg.paths.data_dir)\n\u001b[32m      3\u001b[39m movies_dict = movies_from_pickle(movies_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/open_retina/lib/python3.13/site-packages/omegaconf/dictconfig.py:359\u001b[39m, in \u001b[36mDictConfig.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    355\u001b[39m     \u001b[38;5;28mself\u001b[39m._format_and_raise(\n\u001b[32m    356\u001b[39m         key=key, value=\u001b[38;5;28;01mNone\u001b[39;00m, cause=e, type_override=ConfigAttributeError\n\u001b[32m    357\u001b[39m     )\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_and_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/open_retina/lib/python3.13/site-packages/omegaconf/base.py:231\u001b[39m, in \u001b[36mNode._format_and_raise\u001b[39m\u001b[34m(self, key, value, cause, msg, type_override)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_format_and_raise\u001b[39m(\n\u001b[32m    224\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    225\u001b[39m     key: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     type_override: Any = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    230\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[43mformat_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcause\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtype_override\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtype_override\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/open_retina/lib/python3.13/site-packages/omegaconf/_utils.py:819\u001b[39m, in \u001b[36mformat_and_raise\u001b[39m\u001b[34m(node, key, value, msg, cause, type_override)\u001b[39m\n\u001b[32m    817\u001b[39m         ex = type_override(\u001b[38;5;28mstr\u001b[39m(cause))\n\u001b[32m    818\u001b[39m         ex.\u001b[34m__dict__\u001b[39m = copy.deepcopy(cause.\u001b[34m__dict__\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m819\u001b[39m     \u001b[43m_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    821\u001b[39m object_type: Optional[Type[Any]]\n\u001b[32m    822\u001b[39m object_type_str: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/open_retina/lib/python3.13/site-packages/omegaconf/_utils.py:797\u001b[39m, in \u001b[36m_raise\u001b[39m\u001b[34m(ex, cause)\u001b[39m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    796\u001b[39m     ex.__cause__ = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m797\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex.with_traceback(sys.exc_info()[\u001b[32m2\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/open_retina/lib/python3.13/site-packages/omegaconf/dictconfig.py:351\u001b[39m, in \u001b[36mDictConfig.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m()\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_DEFAULT_MARKER_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConfigKeyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28mself\u001b[39m._format_and_raise(\n\u001b[32m    356\u001b[39m         key=key, value=\u001b[38;5;28;01mNone\u001b[39;00m, cause=e, type_override=ConfigAttributeError\n\u001b[32m    357\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/open_retina/lib/python3.13/site-packages/omegaconf/dictconfig.py:442\u001b[39m, in \u001b[36mDictConfig._get_impl\u001b[39m\u001b[34m(self, key, default_value, validate_key)\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_impl\u001b[39m(\n\u001b[32m    439\u001b[39m     \u001b[38;5;28mself\u001b[39m, key: DictKeyType, default_value: Any, validate_key: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    440\u001b[39m ) -> Any:\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m         node = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_child\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_key\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (ConfigAttributeError, ConfigKeyError):\n\u001b[32m    446\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m default_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _DEFAULT_MARKER_:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/open_retina/lib/python3.13/site-packages/omegaconf/basecontainer.py:73\u001b[39m, in \u001b[36mBaseContainer._get_child\u001b[39m\u001b[34m(self, key, validate_access, validate_key, throw_on_missing_value, throw_on_missing_key)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_child\u001b[39m(\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     66\u001b[39m     key: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m     throw_on_missing_key: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     71\u001b[39m ) -> Union[Optional[Node], List[Optional[Node]]]:\n\u001b[32m     72\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Like _get_node, passing through to the nearest concrete Node.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     child = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate_access\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthrow_on_missing_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthrow_on_missing_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, UnionNode) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_special(child):\n\u001b[32m     81\u001b[39m         value = child._value()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/open_retina/lib/python3.13/site-packages/omegaconf/dictconfig.py:475\u001b[39m, in \u001b[36mDictConfig._get_node\u001b[39m\u001b[34m(self, key, validate_access, validate_key, throw_on_missing_value, throw_on_missing_key)\u001b[39m\n\u001b[32m    472\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate_access:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    477\u001b[39m value: Optional[Node] = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33m_content\u001b[39m\u001b[33m\"\u001b[39m].get(key)\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/open_retina/lib/python3.13/site-packages/omegaconf/dictconfig.py:164\u001b[39m, in \u001b[36mDictConfig._validate_get\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    163\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKey \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not in struct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[43m=\u001b[49m\u001b[43mConfigAttributeError\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/open_retina/lib/python3.13/site-packages/omegaconf/base.py:231\u001b[39m, in \u001b[36mNode._format_and_raise\u001b[39m\u001b[34m(self, key, value, cause, msg, type_override)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_format_and_raise\u001b[39m(\n\u001b[32m    224\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    225\u001b[39m     key: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     type_override: Any = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    230\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[43mformat_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcause\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtype_override\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtype_override\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/open_retina/lib/python3.13/site-packages/omegaconf/_utils.py:899\u001b[39m, in \u001b[36mformat_and_raise\u001b[39m\u001b[34m(node, key, value, msg, cause, type_override)\u001b[39m\n\u001b[32m    896\u001b[39m     ex.ref_type = ref_type\n\u001b[32m    897\u001b[39m     ex.ref_type_str = ref_type_str\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m \u001b[43m_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/open_retina/lib/python3.13/site-packages/omegaconf/_utils.py:797\u001b[39m, in \u001b[36m_raise\u001b[39m\u001b[34m(ex, cause)\u001b[39m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    796\u001b[39m     ex.__cause__ = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m797\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex.with_traceback(sys.exc_info()[\u001b[32m2\u001b[39m])\n",
      "\u001b[31mConfigAttributeError\u001b[39m: Key 'movies_path' is not in struct\n    full_key: paths.movies_path\n    object_type=dict"
     ]
    }
   ],
   "source": [
    "movies_path = get_local_file_path(file_path=cfg.paths.movies_path, cache_folder=cfg.paths.data_dir)\n",
    "\n",
    "movies_dict = movies_from_pickle(movies_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(movies_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also visualize a few seconds of the training video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_to_mp4_video(movies_dict.train[:, :300, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training script, responses are loaded through:\n",
    "\n",
    "```\n",
    "neuron_data_dict = hydra.utils.call(cfg.data_io.responses)\n",
    "```\n",
    "\n",
    "Let's unpack it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(cfg.data_io.responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this may look complex, it effectively amounts to resolving a few intermediate steps in loading the data, and should be read from the inside out.\n",
    "\n",
    "When written more simply, it is equivalent to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_path = get_local_file_path(file_path=cfg.paths.responses_path, cache_folder=cfg.paths.data_dir)\n",
    "\n",
    "responses_dict = load_h5_into_dict(file_path=responses_path)\n",
    "\n",
    "filtered_responses_dict = filter_responses(responses_dict, **cfg.quality_checks)\n",
    "\n",
    "final_responses = make_final_responses(filtered_responses_dict, response_type=\"natural\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is how the final responses will be organised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(final_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding code in `train.py` is:\n",
    "```\n",
    "dataloaders = hydra.utils.instantiate(\n",
    "        cfg.dataloader,\n",
    "        neuron_data_dictionary=neuron_data_dict,\n",
    "        movies_dictionary=movies_dict,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(cfg.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = natmov_dataloaders_v2(\n",
    "    neuron_data_dictionary=final_responses,\n",
    "    movies_dictionary=movies_dict,\n",
    "    allow_over_boundaries=True,\n",
    "    batch_size=128,\n",
    "    train_chunk_size=50,\n",
    "    validation_clip_indices=cfg.dataloader.validation_clip_indices,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compute `data_info`, which is used to initialise certain model components and to save important metadata about stimuli and responses within the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = compute_data_info(neuron_data_dictionary=final_responses, movies_dictionary=movies_dict)\n",
    "\n",
    "pp.pprint(data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant `train.py` section:\n",
    "```\n",
    "cfg.model.n_neurons_dict = data_info[\"n_neurons_dict\"]\n",
    "\n",
    "model = hydra.utils.instantiate(cfg.model, data_info=data_info)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config for the model will contain all the relevant hyperparameters for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(cfg.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the value for `n_neurons_dict` is missing, and needs to be set from data_info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons_dict = data_info[\"n_neurons_dict\"]\n",
    "\n",
    "model = CoreReadout(\n",
    "    in_shape=(1, 1, 108, 108),\n",
    "    hidden_channels=(16, 16),\n",
    "    temporal_kernel_sizes=(1, 1),\n",
    "    spatial_kernel_sizes=(11, 5),\n",
    "    n_neurons_dict=n_neurons_dict,\n",
    "    core_gamma_hidden=0.0,\n",
    "    core_gamma_in_sparse=0.0,\n",
    "    core_gamma_input=0.0,\n",
    "    core_gamma_temporal=40.0,\n",
    "    core_hidden_padding=True,\n",
    "    core_input_padding=False,\n",
    "    cut_first_n_frames_in_core=0,\n",
    "    downsample_input_kernel_size=None,\n",
    "    dropout_rate=0.0,\n",
    "    learning_rate=0.01,\n",
    "    maxpool_every_n_layers=None,\n",
    "    readout_bias=True,\n",
    "    readout_gamma=0.4,\n",
    "    readout_gaussian_masks=True,\n",
    "    readout_gaussian_mean_scale=6.0,\n",
    "    readout_gaussian_var_scale=4.0,\n",
    "    readout_positive=True,\n",
    "    readout_scale=True,\n",
    "    data_info=data_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With data imported, models initialised and dataloaders set up, we can turn to training. \n",
    "\n",
    "```\n",
    "log_folder = os.path.join(cfg.paths.output_dir, cfg.exp_name)\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "logger_array = []\n",
    "for _, logger_params in cfg.logger.items():\n",
    "    logger = hydra.utils.instantiate(logger_params, save_dir=log_folder)\n",
    "    logger_array.append(logger)\n",
    "\n",
    "callbacks = [\n",
    "    hydra.utils.instantiate(callback_params) for callback_params in cfg.get(\"training_callbacks\", {}).values()\n",
    "]\n",
    "\n",
    "trainer = hydra.utils.instantiate(cfg.trainer, logger=logger_array, callbacks=callbacks)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
    "```\n",
    "\n",
    "This section is a bit more involved in `train.py`, to leave flexibility for different loggers and callbacks configurations. We are going to keep it simple here.\n",
    "\n",
    "Let's first initialise a simple tensorboard logger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_save_path = os.path.join(cfg.paths.output_dir, \"notebook_example\")\n",
    "os.makedirs(log_save_path, exist_ok=True)\n",
    "\n",
    "logger = lightning.pytorch.loggers.TensorBoardLogger(\n",
    "    name=\"tensorboard/\",\n",
    "    save_dir=log_save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then some training callbacks (i.e. utility functions that will be called during training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = lightning.pytorch.callbacks.EarlyStopping(\n",
    "    monitor=\"val_correlation\",\n",
    "    patience=10,\n",
    "    mode=\"max\",\n",
    "    verbose=False,\n",
    "    min_delta=0.001,\n",
    ")\n",
    "\n",
    "lr_monitor = lightning.pytorch.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "model_checkpoint = lightning.pytorch.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_correlation\", mode=\"max\", save_weights_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then instantiate the trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = lightning.Trainer(max_epochs=100, logger=logger, callbacks=[early_stopping, lr_monitor, model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can start training. Before doing sp though, we can initialise the tensorboard jupyter integration, to visualize how training progresses.\n",
    "\n",
    "Run the following cell once or twice until the tensorboard extension UI shows up. Once is shows, note that at the beginning it will show no data (unless you have run this notebook before), because we have not started the trainer yet.\n",
    "\n",
    "When you run the cell containing `trainer.fit` you can then come back to the tensorboard extension, reload the window *within the extension* by clicking the refresh icon in the top right, and follow the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir {log_save_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only last important step before calling the trainer is to convert the dictionary of dataloaders we have into a unified iterator that will cycle through all sessions during training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = LongCycler(dataloaders[\"train\"])\n",
    "val_loader = ShortCycler(dataloaders[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we are finally ready to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is done training, we can turn to evaluation.\n",
    "\n",
    "First, let's still use the trainer to see the poisson and correlation performance on each of the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = ShortCycler(dataloaders[\"test\"])\n",
    "trainer.test(model, dataloaders=[train_loader, val_loader, test_loader], ckpt_path=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at further evals, like the fraction of explainable variance explained for an example session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick an example session\n",
    "example_session = list(final_responses.keys())[0]\n",
    "\n",
    "# Extract responses by trial:\n",
    "responses_by_trial = final_responses[example_session].test_by_trial\n",
    "\n",
    "responses_by_trial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test movie for that session:\n",
    "test_movie = dataloaders[\"test\"][example_session].dataset.movies\n",
    "\n",
    "# Pass it through the model: move to gpu and add batch dimension\n",
    "with torch.no_grad():\n",
    "    model_predictions = model.forward(test_movie.to(model.device).unsqueeze(0), data_key=example_session)\n",
    "\n",
    "model_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(feve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to reshape the predictions and responses by trial to match what the function expects\n",
    "\n",
    "feve_score = feve(\n",
    "    rearrange(responses_by_trial, \"neurons time trials -> time trials neurons\")[20:],\n",
    "    model_predictions.squeeze(0).cpu().numpy(),\n",
    ")\n",
    "\n",
    "print(f\"Average FEVe score for session {example_session}: {feve_score.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot an example neuron's predictions and its ground truth response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_idx = 4\n",
    "session_idx = 0\n",
    "\n",
    "\n",
    "example_session = list(final_responses.keys())[session_idx]\n",
    "\n",
    "test_sample = next(iter(dataloaders[\"test\"][example_session]))\n",
    "responses_by_trial = final_responses[example_session].test_by_trial\n",
    "mean_test_responses = final_responses[example_session].test_response\n",
    "\n",
    "input_samples = test_sample.inputs\n",
    "targets = test_sample.targets\n",
    "\n",
    "model.eval()\n",
    "model.cpu()\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructions = model(input_samples.cpu(), example_session)\n",
    "reconstructions = reconstructions.cpu().numpy().squeeze()\n",
    "\n",
    "feve_score = feve(\n",
    "    rearrange(responses_by_trial, \"neurons time trials -> time trials neurons\")[20:],\n",
    "    model_predictions.squeeze(0).cpu().numpy(),\n",
    ")\n",
    "\n",
    "correlations = correlation_numpy(mean_test_responses.T[20:], model_predictions.squeeze(0).cpu().numpy(), axis=0)\n",
    "\n",
    "\n",
    "targets = targets.cpu().numpy().squeeze()\n",
    "window = 750\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.arange(0, window), targets[:window, neuron_idx], label=\"target\")\n",
    "plt.plot(np.arange(20, window), reconstructions[:window, neuron_idx], label=\"prediction\")\n",
    "plt.suptitle(f\"Neuron {neuron_idx} - FEVE: {feve_score[neuron_idx]:.2f} - Correlation: {correlations[neuron_idx]:.2f}\")\n",
    "\n",
    "plt.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_retina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
