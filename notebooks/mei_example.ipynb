{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e2ca20-c60a-4229-a781-0db900ec8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from openretina.insilico.stimulus_optimization.objective import (\n",
    "    AbstractObjective,\n",
    "    IncreaseObjective,\n",
    "    ResponseReducer,\n",
    "    SliceMeanReducer,\n",
    ")\n",
    "from openretina.insilico.stimulus_optimization.optimization_stopper import OptimizationStopper\n",
    "from openretina.insilico.stimulus_optimization.optimizer import optimize_stimulus\n",
    "from openretina.insilico.stimulus_optimization.regularizer import (\n",
    "    ChangeNormJointlyClipRangeSeparately,\n",
    ")\n",
    "from openretina.utils.nnfabrik_model_loading import load_ensemble_model_from_remote\n",
    "from openretina.utils.plotting import play_stimulus, plot_stimulus_composition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcdf4eb-30f1-4e27-b9c0-3473e2f1eb63",
   "metadata": {},
   "source": [
    "First we load an ensemble model from Hoefling, 2024, which is based on two photon recordings of retinal ganglion cells of the mouse retina in response to natural stimuli recorded in the color channels green and uv (in contrast to humans, mice have green and UV sensitive cones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab5cd7a-8264-4703-b7f6-a615c3c4b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_info, ensemble_model = load_ensemble_model_from_remote(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c6d3b6-8036-4ccf-83d4-8ca709d3b48a",
   "metadata": {},
   "source": [
    "Next, we initialize randomly a video stimulus with a global spatiotemporal standard deviation of 0.1, using a batch dimension of 1, 2 color channels, 50 time dimensions, and (18, 16) pixels per frame. We also define a stimulus clipper that makes sure the stimulus stays in a range that makes sense (see hoefling, 2024 for the reasoning of these values). We additionally clip the initial stimulus to this range.\n",
    "\n",
    "This random stimulus will serve as the base for our MEI optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886fd6b-2e3b-4fb9-a82e-e5f1de773f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_shape = (1, 2, 50, 18, 16)\n",
    "\n",
    "stimulus = torch.randn(stimulus_shape, requires_grad=True, device=device)\n",
    "stimulus.data = stimulus.data * 0.1\n",
    "\n",
    "STIMULUS_RANGE_CONSTRAINTS = {\n",
    "    \"norm\": 5.0,\n",
    "    \"x_min_green\": -0.654,\n",
    "    \"x_max_green\": 6.269,\n",
    "    \"x_min_uv\": -0.913,\n",
    "    \"x_max_uv\": 6.269,\n",
    "}\n",
    "stimulus_postprocessor = ChangeNormJointlyClipRangeSeparately(\n",
    "    min_max_values=[\n",
    "        (STIMULUS_RANGE_CONSTRAINTS[\"x_min_green\"], STIMULUS_RANGE_CONSTRAINTS[\"x_max_green\"]),\n",
    "        (STIMULUS_RANGE_CONSTRAINTS[\"x_min_uv\"], STIMULUS_RANGE_CONSTRAINTS[\"x_max_uv\"]),\n",
    "    ],\n",
    "    norm=STIMULUS_RANGE_CONSTRAINTS[\"norm\"],\n",
    ")\n",
    "# clip initial stimulus to desired range\n",
    "stimulus.data = stimulus_postprocessor.process(stimulus.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15397690-d36d-48e8-bb54-d22b06d9e334",
   "metadata": {},
   "source": [
    "Now we pick a session the model supports (i.e. a session it was trained on) and a single neuron within that session.\n",
    "We then setup an objective that the stimulus optimization will be optimizing. \n",
    "\n",
    "With the response reducer, we select the frames [10, 20), and the SingleNeuronObjective makes sure we optimize the response for that single neuron over these frames.\n",
    "\n",
    "The OptimizationStopper defines how many iterations the optimization process takes, and the optimizer init function makes sure we use the SGD optimizer with a learning rate of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d877a443-692a-4eec-8953-73026c3ed559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random session and neuron\n",
    "session_id = list(ensemble_model.members[0].readout.keys())[0]\n",
    "neuron_id = 42\n",
    "\n",
    "response_reducer = SliceMeanReducer(axis=0, start=10, length=10)\n",
    "objective = IncreaseObjective(\n",
    "    ensemble_model, neuron_indices=neuron_id, data_key=session_id, response_reducer=response_reducer\n",
    ")\n",
    "optimization_stopper = OptimizationStopper(max_iterations=10)\n",
    "optimizer_init_fn = partial(torch.optim.SGD, lr=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5087b034-c3a8-43be-986b-d21e18a63ebd",
   "metadata": {},
   "source": [
    "We now optimize the stimulus, we using these parameters, which might take a few seconds if you run this on cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae3e77-3348-45bf-a260-3f8db786efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_stimulus(\n",
    "    stimulus,\n",
    "    optimizer_init_fn,\n",
    "    objective,\n",
    "    optimization_stopper,\n",
    "    stimulus_postprocessor=stimulus_postprocessor,\n",
    "    stimulus_regularization_loss=None,\n",
    ")\n",
    "stimulus_np = stimulus[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa2fe0-8617-46c7-b42c-6ab8a35aa9a5",
   "metadata": {},
   "source": [
    "Let's visualize the stimulus as a video first. The video maps the UV channel to violet, and the green channel to green. It is also jointly normalized across both channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b5099-fc6c-41cf-af6b-29ac234df1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_stimulus(stimulus[0].detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d5a8c8-928a-4e9e-ad53-53bc1fc0e986",
   "metadata": {},
   "source": [
    "In the video you see that the stimulus that maximally activates this particular neuron first shows a green dot, and then switches to an UV dot. Let's visualize the same in a graphic. \n",
    "\n",
    "We plot a decomposition of the stimulus into a temporal trace (top left) and its spatial component (bottom left). On the right side we additionally plot the frequency components of the stimulus, and on the bottom the response of that neuron. We also see here that shortly before the interval the response is optimized for, the uv component of the stimulus strongly increases. In the spatial component you can see that the stimulus has a prominent center/surround structure, which you can observe in the video, too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60bb937-93f3-43b6-9c66-79193871044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(7 * 3, 12))\n",
    "plot_stimulus_composition(\n",
    "    stimulus=stimulus_np,\n",
    "    temporal_trace_ax=axes[0, 0],\n",
    "    freq_ax=axes[0, 1],\n",
    "    spatial_ax=axes[1, 0],\n",
    "    highlight_x_list=[(40, 49)],\n",
    ")\n",
    "neuron_trace = ensemble_model.forward(stimulus, data_key=session_id)[0, :, neuron_id].detach().cpu().numpy()\n",
    "axes[1, 1].set_title(\"Neuron Response\")\n",
    "time_axis = np.arange(30, 30 + len(neuron_trace)) / 30.0\n",
    "axes[1, 1].plot(time_axis, neuron_trace)\n",
    "axes[1, 1].set_xlabel(\"Time [s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc4ba7d-5e49-431c-8e25-2855502114fd",
   "metadata": {},
   "source": [
    "Now, let's implement our own simple objective. Instead of trying to increase the neuron response, we now want to decrease it.\n",
    "\n",
    "To do this we inherit from the AbstractObjective class and implement the forward function ourselves. This function runs a forward path through the model, selects the response of the desired neuron, and then narrows the response to the frames 10 to 20. It than takes the mean of the remaining response, and negates this mean. So now the objective is to increase the negative response of that time interval, which is equivalent to minimizing the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9e965-f310-4bee-aaa2-0390fe9e6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleNeuronMostDepressingObjective(AbstractObjective):\n",
    "    def __init__(self, model, neuron_idx: int, data_key: str | None, response_reducer: ResponseReducer):\n",
    "        super().__init__(model, data_key)\n",
    "        self._neuron_idx = neuron_idx\n",
    "\n",
    "    def forward(self, stimulus: torch.Tensor) -> torch.Tensor:\n",
    "        responses = self.model_forward(stimulus)\n",
    "        # responses.shape = (time, neuron)\n",
    "        single_response = responses[:, self._neuron_idx]\n",
    "\n",
    "        single_score = response_reducer.forward(single_response)\n",
    "        negative_score = -single_score\n",
    "        return negative_score\n",
    "\n",
    "\n",
    "mdi_objective = SingleNeuronMostDepressingObjective(\n",
    "    ensemble_model, neuron_idx=neuron_id, data_key=session_id,\n",
    "    response_reducer=SliceMeanReducer(axis=0, start=10, length=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53b23c6-8bd0-4244-9689-8a950e6e0306",
   "metadata": {},
   "source": [
    "So let's initialize a new random stimulus and run optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8384a45-3164-4f2c-bdae-73c325799c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random stimulus with stdvar 0.1 clipped to range\n",
    "mdi = torch.randn(stimulus_shape, requires_grad=True, device=device)\n",
    "mdi.data = mdi.data * 0.1\n",
    "stimulus.data = stimulus_postprocessor.process(mdi.data)\n",
    "\n",
    "# optimize stimulus\n",
    "optimize_stimulus(\n",
    "    mdi,\n",
    "    optimizer_init_fn,\n",
    "    mdi_objective,\n",
    "    OptimizationStopper(max_iterations=10),\n",
    "    stimulus_postprocessor=stimulus_postprocessor,\n",
    "    stimulus_regularization_loss=None,\n",
    ")\n",
    "mdi_np = mdi[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c426e3a7-7921-484c-ba33-3eda16db78ee",
   "metadata": {},
   "source": [
    "Let's play the stimulus as a video, does it look different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5b3c3-8854-4e8c-bab4-fe65291b3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_stimulus(mdi[0].detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da54a7fd-18df-4bd4-993d-19f1baea6685",
   "metadata": {},
   "source": [
    "As you can see in the video, the stimulus is way more noisy then the most exciting stimulus. This is reasonable, the neuron probably does not respond at all to most stimuli, including noisy stimuli. So the optimization found a specific noisy stimulus for which the activity of the neuron is low.\n",
    "For a neuron type called suppressed-by-contrast cells, which decrease their activity below baseline rate for contrasts, the optimized stimulus would likely be less noisy (if you want to try this out, in session '3_ventral1_20201021' neuronid 100 is a suppressed-by-contrast cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b8950-f779-4c17-b34a-fc2e19c012bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(7 * 3, 12))\n",
    "plot_stimulus_composition(\n",
    "    stimulus=mdi_np,\n",
    "    temporal_trace_ax=axes[0, 0],\n",
    "    freq_ax=axes[0, 1],\n",
    "    spatial_ax=axes[1, 0],\n",
    "    highlight_x_list=[(40, 49)],\n",
    ")\n",
    "neuron_trace = ensemble_model.forward(mdi, data_key=session_id)[0, :, neuron_id].detach().cpu().numpy()\n",
    "axes[1, 1].set_title(\"Neuron Response\")\n",
    "time_axis = np.arange(30, 30 + len(neuron_trace)) / 30.0\n",
    "axes[1, 1].plot(time_axis, neuron_trace)\n",
    "axes[1, 1].set_xlabel(\"Time [s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900da04-d397-42fe-b865-21dff8da15bf",
   "metadata": {},
   "source": [
    "In principle, you can optimize any objective that you can write down in torch and that is differentiable.\n",
    "Here is an objective that includes more neurons and tries to find a stimulus that leads to a strong response of one neuron and a weak response from all other neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc043bd-99a9-4139-a1bd-506d2aafb4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseActivationOfFieldObjective(AbstractObjective):\n",
    "    def __init__(self, model, data_key: str | None):\n",
    "        super().__init__(model, data_key)\n",
    "\n",
    "    def forward(self, stimulus: torch.Tensor) -> torch.Tensor:\n",
    "        # responses.shape = (time, neuron)\n",
    "        responses = self.model_forward(stimulus)\n",
    "        # we do not use a response reducer here, but just take the mean of over the time dimension \n",
    "        mean_response = responses.mean(axis=0)\n",
    "        max_response_neuron = responses.max()\n",
    "        \n",
    "        score = 2 * max_response_neuron - mean_response.sum() \n",
    "        return score\n",
    "\n",
    "\n",
    "sparse_objective = SparseActivationOfFieldObjective(\n",
    "    ensemble_model, data_key=session_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1fb9cf-895b-4920-af00-0ec1fbbdd73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random stimulus with stdvar 0.1 clipped to range\n",
    "sparse_stim = torch.randn(stimulus_shape, requires_grad=True, device=device)\n",
    "sparse_stim.data = sparse_stim.data * 0.1\n",
    "sparse_stim.data = stimulus_postprocessor.process(sparse_stim.data)\n",
    "\n",
    "# optimize stimulus\n",
    "optimize_stimulus(\n",
    "    sparse_stim,\n",
    "    optimizer_init_fn,\n",
    "    sparse_objective,\n",
    "    OptimizationStopper(max_iterations=50),\n",
    "    stimulus_postprocessor=stimulus_postprocessor,\n",
    "    stimulus_regularization_loss=None,\n",
    ")\n",
    "sparse_stim_np = sparse_stim[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981932ea-b58e-4a40-ab4a-17b28acae709",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_stimulus(sparse_stim[0].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db2cb6-bfda-49ed-8f1d-fd88c35a04c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(7 * 3, 12))\n",
    "plot_stimulus_composition(\n",
    "    stimulus=mdi_np,\n",
    "    temporal_trace_ax=axes[0, 0],\n",
    "    freq_ax=axes[0, 1],\n",
    "    spatial_ax=axes[1, 0],\n",
    "    highlight_x_list=[(40, 49)],\n",
    ")\n",
    "neuron_trace = ensemble_model.forward(sparse_stim, data_key=session_id)[0, :, :].detach().cpu().numpy()\n",
    "axes[1, 1].set_title(\"Neuron Response\")\n",
    "time_axis = np.arange(30, 30 + len(neuron_trace)) / 30.0\n",
    "for i in range(neuron_trace.shape[-1]):\n",
    "    axes[1, 1].plot(time_axis, neuron_trace[:, i])\n",
    "axes[1, 1].set_xlabel(\"Time [s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a7cd4-b7c2-42bf-b99d-eec6340865ac",
   "metadata": {},
   "source": [
    "If you look at the neuron responses above, it partially worked, you see a trend that three neurons activate very strongly, and most of the remaining ones show a weak response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06763f2-91d1-4794-ab4c-33fb2d12063f",
   "metadata": {},
   "source": [
    "If you want to read up on more involved optimization objective for stimuli, you can take a look at the following paper:\n",
    "[Most discriminative stimuli for functional cell type clustering](https://openreview.net/forum?id=9W6KaAcYlr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1a76bf-eec3-4ad4-9560-f2a7fe4ec369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
