{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef90167-0a6a-48ae-90a8-48bfd2f71e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from openretina.data_io.hoefling_2024.constants import FRAME_RATE_MODEL\n",
    "from openretina.models.core_readout import CoreReadout, load_core_readout_from_remote\n",
    "from openretina.insilico.stimulus_optimization.objective import ContrastiveNeuronObjective, SliceMeanReducer, IncreaseObjective\n",
    "from openretina.insilico.stimulus_optimization.optimizer import optimize_stimulus\n",
    "from openretina.insilico.stimulus_optimization.optimization_stopper import OptimizationStopper\n",
    "from openretina.utils.plotting import play_stimulus, plot_stimulus_composition\n",
    "from openretina.insilico.stimulus_optimization.regularizer import (ChangeNormJointlyClipRangeSeparately,\n",
    "    TemporalGaussianLowPassFilterProcessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c385f-2fe7-4db5-8008-14f3df8f1987",
   "metadata": {},
   "source": [
    "Load the pretrained neural network hoefling 2024 trained on low resolution videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b664e909-87c9-4708-82cc-5adc69bea141",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = load_core_readout_from_remote(\"hoefling_2024_base_low_res\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef0b040-7782-4e53-be4a-29747e39ed4a",
   "metadata": {},
   "source": [
    "Load the neural traces and the associated meta information based on the config of the model, and then extract the RGC group assignment for every neuron included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21351bd0-606e-4eec-8d46-a870b6c0fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract group assignments for each readout \n",
    "group_assignment = np.concatenate([model.data_info[\"sessions_kwargs\"][k][\"group_assignment\"] for k in model.readout.readout_keys()])\n",
    "type_to_idc = {int(t): np.where(group_assignment == t)[0].tolist() for t in set(group_assignment)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce7f43-e6f3-4612-8c78-ee8e022d27c4",
   "metadata": {},
   "source": [
    "Define a function that optimizes a stimulus based on an objective and then plots this optimized stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7113f8c-5fa7-4d40-a4f2-d4ec34acf07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_and_plot_stimulus(stimulus_shape, objective) -> None:\n",
    "    torch.manual_seed(40)\n",
    "    stimulus = torch.randn(stimulus_shape, requires_grad=True, device=device)\n",
    "    stimulus_clipper = ChangeNormJointlyClipRangeSeparately(\n",
    "        min_max_values=[(-0.6, 6.2), (-0.9, 6.2)],\n",
    "        norm=30.0,\n",
    "    )\n",
    "    stimulus_lowpass_filter = TemporalGaussianLowPassFilterProcessor(sigma=0.5, kernel_size=5, device=device)\n",
    "    stimulus_postprocessor_list = [stimulus_clipper, stimulus_lowpass_filter]\n",
    "\n",
    "    # Clip the initial stimulus to the expected range\n",
    "    stimulus.data = stimulus_clipper.process(stimulus.data * 0.1)\n",
    "\n",
    "    optimize_stimulus(\n",
    "        stimulus,\n",
    "        optimizer_init_fn=partial(torch.optim.SGD, lr=100.0),\n",
    "        objective_object=objective,\n",
    "        optimization_stopper=OptimizationStopper(max_iterations=10),\n",
    "        stimulus_postprocessor=stimulus_postprocessor_list,\n",
    "    )\n",
    "\n",
    "    fig_axes_tuple = plt.subplots(2, 2, figsize=(7 * 3, 12))\n",
    "    axes: np.ndarray = fig_axes_tuple[1]  # type: ignore\n",
    "\n",
    "    stim_length = stimulus_shape[2]\n",
    "    plot_stimulus_composition(\n",
    "        stimulus=stimulus[0].detach().cpu().numpy(),\n",
    "        temporal_trace_ax=axes[0, 0],\n",
    "        freq_ax=axes[0, 1],\n",
    "        spatial_ax=axes[1, 0],\n",
    "        highlight_x_list=[(stim_length-10,stim_length-1)],\n",
    "    )\n",
    "    return stimulus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd029b2-eeab-4a39-8f67-ea4a20ca4f75",
   "metadata": {},
   "source": [
    "Define two objective functions:\n",
    "- objective_mei optimizes an most exciting stimulus such that cells of type 28 activate strongly.\n",
    "- objective_mds optimizes a most discriminatory stimulus such that cells of type 28 activate strongly but minimizes the response of other on and off cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381dcf6a-ffc7-4d6f-8a6c-3d0cb9168110",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_shape = model.stimulus_shape(time_steps=40)\n",
    "\n",
    "reducer = SliceMeanReducer(axis=0, start=10, length=10)\n",
    "objective_mei = IncreaseObjective(\n",
    "    model,\n",
    "    neuron_indices=type_to_idc[28],\n",
    "    data_key=None,\n",
    "    response_reducer=reducer,\n",
    ")\n",
    "\n",
    "off_cell_idc = sum([type_to_idc[i] for i in range(1, 10)], [])\n",
    "on_off_cell_idc = sum([type_to_idc[i] for i in range(10, 15)], [])\n",
    "on_cell_idc = sum([type_to_idc[i] for i in range(15, 28)], [])\n",
    "objective_mds = ContrastiveNeuronObjective(\n",
    "    model, \n",
    "    on_cluster_idc=type_to_idc[28],\n",
    "    off_cluster_idc_list=[on_cell_idc, off_cell_idc],\n",
    "    data_key=None,\n",
    "    response_reducer=reducer,\n",
    "    temperature=1.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8da31f-78fa-4595-aba7-0c013e8e1347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stimulus_mei = optimize_and_plot_stimulus(stimulus_shape, objective_mei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f769c8-b08d-4e15-ab50-8109307005ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_mds = optimize_and_plot_stimulus(stimulus_shape, objective_mds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfa252d-7027-4ef3-a022-a7302d9f0007",
   "metadata": {},
   "source": [
    "We now use these stimuli and simulate the responses of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93959da-d441-459f-8bed-c8d4580a36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_mds = model.forward(stimulus_mds)\n",
    "responses_mds_np = responses_mds[0].detach().transpose(1, 0).cpu().numpy()\n",
    "responses_mei = model.forward(stimulus_mei)\n",
    "responses_mei_np = responses_mei[0].detach().transpose(1, 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b7c31c-21aa-4b51-95cd-82dc3ed03d4f",
   "metadata": {},
   "source": [
    "For the MEI we see that the average response to neurons of group 28 is high, but the response of the other on cells is even higher.\n",
    "In contrast, the average response of the on cells to the MDS stimulus is lower compared to the response of cells of group 28 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637c2a23-727a-4f01-ba80-12df55ba4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 3), sharey=True)\n",
    "\n",
    "offset = 20\n",
    "time = np.arange(offset, offset + responses_mds_np[0].shape[0]) / FRAME_RATE_MODEL\n",
    "for resp, linestyle in [(responses_mei_np, \"--\"), (responses_mds_np, \"-\")]:\n",
    "    l1, = ax.plot(time, resp[type_to_idc[28]].mean(axis=0), label=\"Group 28\", color=\"red\", linestyle=linestyle)\n",
    "    l2, = ax.plot(time, resp[on_cell_idc].mean(axis=0), label=\"On Cells\", color=\"green\", linestyle=linestyle)\n",
    "    l3, = ax.plot(time, resp[off_cell_idc].mean(axis=0), label=\"Off Cells\", color=\"purple\", linestyle=linestyle)\n",
    "\n",
    "ax.set_ylabel(\"Average Responses [AU]\")\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "ax.fill_betweenx(\n",
    "    ax.get_ylim(), \n",
    "    (offset + reducer.start) / FRAME_RATE_MODEL, \n",
    "    (offset + reducer.start + reducer.length) / FRAME_RATE_MODEL, \n",
    "    color=\"k\", alpha=0.1\n",
    ")\n",
    "ax.legend(handles=[l1, l2, l3], loc=\"upper center\", bbox_to_anchor=(0.4, 1.00))\n",
    "sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
