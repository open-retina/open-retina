{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40797bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from openretina.insilico.VectorFieldAnalysis.vector_field_analysis import (\n",
    "    plot_untreated_vectorfield,\n",
    "    plot_clean_vectorfield,\n",
    ")\n",
    "from openretina.models.core_readout import load_core_readout_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b828",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9001257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = load_core_readout_from_remote(\n",
    "#     \"karamanlis_2024_base\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# )\n",
    "\n",
    "# TO DO : Repair loading function again\n",
    "model = load_core_readout_model(\n",
    "    \"/home/baptiste/Documents/LabPipelines/open-retina/openretina_assets/runs/core_readout_goldin_2022/2025-09-01_10-50-49/checkpoints/epoch=69_val_correlation=0.000.ckpt\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random session\n",
    "session_id = list(model.readout.keys())[-1]\n",
    "print(session_id)\n",
    "n_neurons = model.readout[session_id].outdims\n",
    "print(f\"Number of neurons: {n_neurons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60211cda",
   "metadata": {},
   "source": [
    "# Load natural images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252afd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openretina.data_io.goldin_2022.responses import load_all_responses\n",
    "from openretina.data_io.goldin_2022.stimuli import load_all_stimuli\n",
    "\n",
    "# Load training images (Feel free to use another dataset instead but make sure the preprocessing is correct)\n",
    "movies = load_all_stimuli(\n",
    "    base_data_path=\"/home/baptiste/Documents/LabPipelines/open-retina/notebooks/data/omarre_lab/goldin_2022\",\n",
    "    normalize_stimuli=True,\n",
    "    specie='mouse'\n",
    ")\n",
    "responses = load_all_responses(\n",
    "    base_data_path=\"/home/baptiste/Documents/LabPipelines/open-retina/notebooks/data/omarre_lab/goldin_2022\",\n",
    "    specie='mouse'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe32ed",
   "metadata": {},
   "source": [
    "# Test Goldin 2022 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movies = movies[session_id].test_dict['test']\n",
    "test_responses = responses[session_id].test_dict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99acafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Load the HDF5 file\n",
    "file_path = f'data/omarre_lab/goldin_2022/{session_id}.h5'\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    # Convert HDF5 file to dictionary recursively\n",
    "    def h5_to_dict(item):\n",
    "        if isinstance(item, h5py.Dataset):\n",
    "            return item[()]\n",
    "        elif isinstance(item, h5py.Group):\n",
    "            return {key: h5_to_dict(item[key]) for key in item.keys()}\n",
    "\n",
    "    # Convert the entire file to a dictionary\n",
    "    full_test = h5_to_dict(f['test'])\n",
    "    print(\"Available keys in the file:\", list(f.keys()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reliability_list = []\n",
    "for cell in full_test['repeats'].keys():\n",
    "    odd_trials = full_test['repeats'][cell][::2]\n",
    "    even_trials = full_test['repeats'][cell][1::2]\n",
    "    reliability_list.append(np.corrcoef(odd_trials.mean(axis=0), even_trials.mean(axis=0))[0,1])\n",
    "reliability_list = np.array(reliability_list)\n",
    "print(f\"Average reliability across cells: {np.mean(reliability_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df9a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movies.shape, test_responses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d72e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predict_responses = model(torch.tensor(test_movies).swapaxes(0,1).unsqueeze(1).to(device)).cpu().detach().numpy()[:,0,:].swapaxes(0,1)\n",
    "predict_responses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_score(cell_id):\n",
    "    return np.corrcoef(test_responses[cell_id], predict_responses[cell_id])[0,1]\n",
    "all_scores = [get_test_score(i) for i in range(n_neurons)]\n",
    "print(f\"Average r2 test score across cells: {np.mean(all_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b247336",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_scores = [all_scores[i] / np.sqrt(reliability_list[i]) for i in range(n_neurons)]\n",
    "print(f\"Average corrected r2 test score across cells: {np.mean(corrected_scores)}\")\n",
    "print(\"Even better than reported in the paper :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3ff8e",
   "metadata": {},
   "source": [
    "# Prepare natural movie dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOTFIX : Add input_shape to data_info to keep the original function intact\n",
    "model.data_info = {}\n",
    "model.data_info['input_shape'] = movies[session_id].train.swapaxes(0, 1).shape[1:]\n",
    "# movies[session_id].train.expand_dims(1)\n",
    "# movies= np.expand_dims(movies[session_id].train, axis=1)\n",
    "movies = movies[session_id].train.swapaxes(0, 1)  # put channels first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a0968",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "movies, n_empty_frames = prepare_movies_dataset(model, session_id, device = device, image_library = movies, normalize_movies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8903e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last frame of an example movie with both channels side by side\n",
    "example_idx = 20  # First movie as example\n",
    "last_frame = movies[example_idx, :, -1, :, :]  # Shape: (2, 72, 64)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# First channel (channel 0)\n",
    "im1 = axes[0].imshow(last_frame[0], cmap='grey', vmin=movies[:, 0, :, :].min(), vmax=movies[:, 0, :, :].max())\n",
    "axes[0].set_title('First Channel')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "axes[0].axis('off')\n",
    "# Optional : Second channel (channel 1)\n",
    "# im2 = axes[1].imshow(last_frame[1], cmap='Purples', vmin=movies[:, 1, :, :].min(), vmax=movies[:, 1, :, :].max())\n",
    "# axes[1].set_title('Second Channel')\n",
    "# # plt.colorbar(im2, ax=axes[1])\n",
    "axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"First channel range on this image: [{last_frame[0].min():.3f}, {last_frame[0].max():.3f}]\")\n",
    "# print(f\"Second channel range: [{last_frame[1].min():.3f}, {last_frame[1].max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ea80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id = 10 # For Goldin 2022, mouse => Use 10 for an example contrast cell\n",
    "cell_reliability = reliability_list[cell_id]\n",
    "cell_test_score = corrected_scores[cell_id]\n",
    "print(f\"Cell {cell_id} reliability: {cell_reliability}\")\n",
    "print(f\"Cell {cell_id} test score: {cell_test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The slow cell\n",
    "lsta_library, response_library = compute_lsta_library(model, movies, session_id, cell_id, batch_size=64, integration_window=(10,15), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c05a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check some sample responses, making sure the integrity of the response profile is predicted and we did not cut it too short.\n",
    "\n",
    "plt.plot(response_library[0, :, cell_id])\n",
    "plt.plot(response_library[1, :, cell_id])\n",
    "plt.plot(response_library[2, :, cell_id])\n",
    "plt.plot(response_library[3, :, cell_id])\n",
    "plt.plot(response_library[4, :, cell_id])\n",
    "plt.plot(response_library[5, :, cell_id])\n",
    "plt.xlabel('Time (frames)')\n",
    "plt.ylabel('Cell predicted Response (au)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dbf518",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsta_library.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsta_library.mean()\n",
    "lsta_library.max()\n",
    "lsta_library.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a694292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now plot an example LSTA and the corresponding image\n",
    "\n",
    "image = 500\n",
    "channel = 0\n",
    "lsta = lsta_library[image, channel]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# image\n",
    "axes[0].imshow(movies[image,0,-1], cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# LSTA\n",
    "axes[1].imshow(lsta, cmap='bwr', vmin=-abs(lsta).max(), vmax=abs(lsta).max())\n",
    "axes[1].set_title('LSTA (Local Spatiotemporal Average)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47984ab4",
   "metadata": {},
   "source": [
    "# Do PCA on the LSTA library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select channel\n",
    "channel = 0\n",
    "# lsta_library = lsta_library[:, :, :]\n",
    "\n",
    "PC1, PC2, explained_variance = get_pc_from_pca(model, channel, lsta_library, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf190a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the images onto PCA space\n",
    "images = movies[:,channel,-1,:,:]\n",
    "images_coordinate = get_images_coordinate(images, PC1, PC2, plot=False)\n",
    "\n",
    "images_coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_coordinate.shape, lsta_library.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304dfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the vector field of the LSTA in PCA space\n",
    "from openretina.insilico.VectorFieldAnalysis.vector_field_analysis import plot_untreated_vectorfield\n",
    "\n",
    "fig = plot_untreated_vectorfield(lsta_library, channel = 0, PC1 = PC1, PC2 = PC2, images_coordinate = images_coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d39a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openretina.insilico.VectorFieldAnalysis.vector_field_analysis import plot_clean_vectorfield\n",
    "\n",
    "fig = plot_clean_vectorfield(\n",
    "    lsta_library,\n",
    "    channel,\n",
    "    PC1,\n",
    "    PC2,\n",
    "    images,\n",
    "    images_coordinate,\n",
    "    explained_variance,\n",
    "    x_bins=31,\n",
    "    y_bins=31,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# ADD the firing rate by the side + mention cell types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31f3a6c",
   "metadata": {},
   "source": [
    "# Create all arrowplots of a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openretina.insilico.VectorFieldAnalysis.vector_field_analysis import plot_clean_vectorfield\n",
    "\n",
    "\n",
    "# for cell_id in range(n_neurons):\n",
    "#     print(f\"Processing cell {cell_id}...\")\n",
    "#     lsta_library, response_library = compute_lsta_library(model, movies, session_id, cell_id, batch_size=64, device=device)\n",
    "#     PC1, PC2, explained_variance = get_pc_from_pca(model, channel, lsta_library, plot=True)\n",
    "#     images_coordinate = get_images_coordinate(images, PC1, PC2, plot=False)\n",
    "#     fig = plot_clean_vectorfield(\n",
    "#         lsta_library,\n",
    "#         channel,\n",
    "#         PC1,\n",
    "#         PC2,\n",
    "#         images,\n",
    "#         images_coordinate,\n",
    "#         explained_variance,\n",
    "#         x_bins=31,\n",
    "#         y_bins=31,\n",
    "#     )\n",
    "#     fig.savefig(f\"goldin_2022_vector_fields/cell_{cell_id}_mouse.png\", dpi=300, bbox_inches='tight')\n",
    "#     plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_retina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
