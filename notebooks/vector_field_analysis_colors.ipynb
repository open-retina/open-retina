{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40797bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch    \n",
    "from sklearn.decomposition import PCA\n",
    "import hydra\n",
    "\n",
    "from openretina.insilico.VectorFieldAnalysis.vector_field_analysis import *\n",
    "from openretina.models.core_readout import load_core_readout_from_remote\n",
    "from openretina.data_io.hoefling_2024.stimuli import movies_from_pickle\n",
    "from openretina.utils.file_utils import get_local_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b828",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = load_core_readout_from_remote(\n",
    "    \"hoefling_2024_base_high_res\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random session\n",
    "session_id = list(model.readout.keys())[0]\n",
    "print(session_id)\n",
    "n_neurons = model.readout[session_id].outdims\n",
    "print(f\"Number of neurons: {n_neurons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60211cda",
   "metadata": {},
   "source": [
    "# Load natural images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58277a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Hoefling et al, let's load training data\n",
    "with hydra.initialize(config_path=os.path.join(\"..\", \"configs\"), version_base=\"1.3\"):\n",
    "    cfg = hydra.compose(config_name=\"hoefling_2024_core_readout_high_res.yaml\")\n",
    "\n",
    "movies_path = get_local_file_path(file_path=cfg.paths.movies_path, cache_folder=cfg.paths.data_dir)\n",
    "\n",
    "movies_dict = movies_from_pickle(movies_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72607b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(movies_dict.train[0,1300]), movies_dict.train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd1ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 3000\n",
    "rate = movies_dict.train.shape[1] // n_images\n",
    "natural_images_library = movies_dict.train[:, ::rate, :, :].swapaxes(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb9f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_images_library.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a0968",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "movies, n_empty_frames = prepare_movies_dataset(model, session_id,\n",
    "    normalize_movies=False, # Already normalized\n",
    "    image_library=natural_images_library, n_image_frames=16, device = device)\n",
    "# 16 frames * 30 Hz = 0.53 seconds integration window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8903e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last frame of an example movie with both channels side by side\n",
    "example_idx = 135  # First movie as example\n",
    "last_frame = movies[example_idx, :, -16]  # Shape: (2, 72, 64)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# First channel (channel 0)\n",
    "im1 = axes[0].imshow(last_frame[0], cmap='Greens', vmin=movies[:, 0].min(), vmax=movies[:, 0].max())\n",
    "axes[0].set_title('First Channel')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "axes[0].axis('off')\n",
    "# Optional : Second channel (channel 1) \n",
    "im2 = axes[1].imshow(last_frame[1], cmap='Purples', vmin=movies[:, 1].min(), vmax=movies[:, 1].max())\n",
    "axes[1].set_title('Second Channel')\n",
    "# plt.colorbar(im2, ax=axes[1])\n",
    "axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"First channel range: [{last_frame[0].min():.3f}, {last_frame[0].max():.3f}]\")\n",
    "# print(f\"Second channel range: [{last_frame[1].min():.3f}, {last_frame[1].max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ea80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id = 15  # LInear example | cell_id = 33 NONLINEAR Example\n",
    "lsta_library, response_library = compute_lsta_library(\n",
    "    model,\n",
    "    movies,\n",
    "    session_id,\n",
    "    cell_id,\n",
    "    integration_window=(0, 16),  # Integration window for the LSTA\n",
    "    batch_size=64,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b97d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsta_library.shape, response_library.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c05a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check some sample responses, making sure the integrity of the response profile is predicted and we did not cut it too short.\n",
    "\n",
    "plt.plot(response_library[0, :, cell_id])\n",
    "plt.plot(response_library[1, :, cell_id])\n",
    "plt.plot(response_library[2, :, cell_id])\n",
    "plt.plot(response_library[3, :, cell_id])\n",
    "plt.plot(response_library[4, :, cell_id])\n",
    "plt.plot(response_library[5, :, cell_id])\n",
    "plt.xlabel('Time (frames)')\n",
    "plt.ylabel('Cell predicted Response (au)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a694292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now plot an example LSTA and the corresponding image\n",
    "\n",
    "image = 85\n",
    "channel = 1\n",
    "lsta = lsta_library[image, channel]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# image\n",
    "axes[0].imshow(movies[image,0,-1], cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# LSTA\n",
    "axes[1].imshow(lsta, cmap='bwr', vmin=-abs(lsta).max(), vmax=abs(lsta).max())\n",
    "axes[1].set_title('LSTA (Local Spatiotemporal Average)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47984ab4",
   "metadata": {},
   "source": [
    "# Do PCA on the LSTA library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select channel\n",
    "channel = 0\n",
    "# lsta_library = lsta_library[:, :, :]\n",
    "\n",
    "PC1, PC2, explained_variance = get_pc_from_pca(model, channel, lsta_library, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf190a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the images onto PCA space\n",
    "images = movies[:,channel,-1,:,:]\n",
    "images_coordinate = get_images_coordinate(images, PC1, PC2, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304dfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the vector field of the LSTA in PCA space\n",
    "from openretina.insilico.VectorFieldAnalysis.vector_field_analysis import plot_untreated_vectorfield\n",
    "\n",
    "fig = plot_untreated_vectorfield(lsta_library[:, channel, :, :], PC1, PC2, images_coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78395db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsta_library.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d39a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openretina.insilico.VectorFieldAnalysis.vector_field_analysis import plot_clean_vectorfield\n",
    "fig = plot_clean_vectorfield(\n",
    "    lsta_library[:, channel, :, :],\n",
    "    channel,\n",
    "    PC1,\n",
    "    PC2,\n",
    "    images,\n",
    "    images_coordinate,\n",
    "    explained_variance,\n",
    "    x_bins=31,\n",
    "    y_bins=31,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# ADD the firing rate by the side + mention cell types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31f3a6c",
   "metadata": {},
   "source": [
    "# Create all arrowplots of a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openretina.insilico.VectorFieldAnalysis.vector_field_analysis import plot_clean_vectorfield\n",
    "\n",
    "\n",
    "for cell_id in range(n_neurons):\n",
    "    print(f\"Processing cell {cell_id}...\")\n",
    "    lsta_library, response_library = compute_lsta_library(model, movies, session_id, cell_id, batch_size=64, device=device)\n",
    "    PC1, PC2, explained_variance = get_pc_from_pca(model, channel, lsta_library, plot=True)\n",
    "    images_coordinate = get_images_coordinate(images, PC1, PC2, plot=False)\n",
    "    fig = plot_clean_vectorfield(\n",
    "        lsta_library,\n",
    "        channel,\n",
    "        PC1,\n",
    "        PC2,\n",
    "        images,\n",
    "        images_coordinate,\n",
    "        explained_variance,\n",
    "        x_bins=31,\n",
    "        y_bins=31,\n",
    "    )\n",
    "    fig.savefig(f\"karamanlis_vector_fields/cell_{cell_id}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_retina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
