defaults:
  - _self_
  - quality_checks: hoefling_2024
  - dataloader@natmov_dataloader: hoefling_2024 # looks for default under "dataloader" and names it "natmov_dataloader"

exp_name: example_core_readout_filtered
cache_folder: "./cache_folder/"
movies_path: "https://gin.g-node.org/teulerlab/open-retina/raw/master/stimuli/eulerlab/rgc_natstim_72x64_joint_normalized_2024-10-11.pkl"
responses_path: "https://gin.g-node.org/teulerlab/open-retina/raw/master/responses/eulerlab/rgc_natstim_2024-08-14.h5"
save_folder: exp/
max_epochs: 100
seed: 42

matmul_precision:
  _target_: torch.set_float32_matmul_precision
  precision: medium

core_readout:
  in_channels: 2
  features_core: [16, 16, 16, 16]
  temporal_kernel_sizes: [15, 15, 7, 7]
  spatial_kernel_sizes: [15, 15, 7, 7]
  in_shape_readout: [16, 120, 18, 16]
  scale: True
  bias: True
  gaussian_masks: True
  gaussian_mean_scale: 6.0
  gaussian_var_scale: 4.0
  positive: False  # Set to True for positive readout features
  gamma_readout: 0.4
  # core regularization weights
  gamma_input: 0.0
  gamma_in_sparse: 0.0
  gamma_hidden: 0.0
  gamma_temporal: 40.0
  learning_rate: 0.01
  maxpool_every_n_layers: 2
  cut_first_n_frames_in_core: 30
  dropout_rate: 0.0
  # downsample_input_kernel_size: [1, 4, 4]  # to reproduce Hoefling input size of 18x16px

dataloader:
  batch_size: null
  num_workers: 0

trainer:
  precision: "16-mixed"
  accumulate_grad_batches: 1


loggers:
  csv:
    _target_: lightning.pytorch.loggers.CSVLogger
  tensorboard:
    _target_: lightning.pytorch.loggers.TensorBoardLogger

training_callbacks:
  early_stopping:
    _target_: lightning.pytorch.callbacks.early_stopping.EarlyStopping
    monitor: "val_correlation"
    min_delta: 0.001
    patience: 15
    verbose: True
    mode: "max"
  lr_monitor:
    _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: "epoch"
    log_momentum: true
    log_weight_decay: true
