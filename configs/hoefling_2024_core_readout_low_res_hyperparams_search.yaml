defaults:
  - data_io: hoefling_2024
  - quality_checks: hoefling_2024
  - dataloader: hoefling_2024
  - model: base_core_readout
  - training_callbacks:
    - early_stopping
    - lr_monitor
    - model_checkpoint
  - logger:
    - tensorboard
    - csv
    - mlflow
  - trainer: default_deterministic
  - hydra: default
  - override hydra/sweeper: optuna
  - override hydra/sweeper/sampler: tpe
  - _self_ # values in this config will overwrite the defaults

exp_name: hoefling_2024_core_readout_low_res_filtered_hyperparams_search
seed: 42
check_stimuli_responses_match: false

dataloader:
  batch_size: 64

objective_target: val_correlation

hydra:
  run:
    dir: ${paths.log_dir}
  sweeper:
    sampler:
      seed: 42
    direction: maximize
    study_name: ${exp_name}
    storage: null
    n_trials: 20
    n_jobs: 1
    params:
      model.hidden_channels: choice([8, 8, 8, 8], [16, 16, 16, 16], [32, 32, 32, 32])
      model.core_gamma_input: interval(1e-5, 1e-2)
      

model:
  in_shape: [2, 150, 18, 16]
  hidden_channels: [16, 16, 16, 16]
  temporal_kernel_sizes: [15, 15, 7, 7]
  spatial_kernel_sizes: [15, 15, 7, 7]
  core_hidden_padding: true
  core_input_padding: true
  cut_first_n_frames_in_core: 30
  maxpool_every_n_layers: 2
  # downsample_input_kernel_size: [1, 4, 4]  # to reproduce 18x16px lowres input

paths:
  cache_dir: ${oc.env:OPENRETINA_CACHE_DIRECTORY} # Remote files are downloaded to this location
  data_dir: ${paths.cache_dir}/data/ # Folder where local files are read from.
  log_dir: "." # Used as parent for output_dir. Will store train logs.
  output_dir: ${hydra:runtime.output_dir} # Modify subpaths in the "hydra/default.yaml" config
  movies_path: "https://huggingface.co/datasets/open-retina/open-retina/blob/main/euler_lab/hoefling_2024/stimuli/rgc_natstim_18x16_joint_normalized_2024-01-11.zip"
  responses_path: "https://huggingface.co/datasets/open-retina/open-retina/resolve/main/euler_lab/hoefling_2024/responses/rgc_natstim_2024-08-14.zip"

matmul_precision:
  _target_: torch.set_float32_matmul_precision
  precision: highest

trainer:
  max_epochs: 100
  accumulate_grad_batches: 1
  gradient_clip_val: 1
